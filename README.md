# Log-Access-Analytics

### A DevOps CICD environment PoC/Test
### Introduction
This is a system for registering and analyzing logs generated in a PetShop system. 
There is three main aspects of this project, the Jenkins CICD machine, the app for injesting and generating the metrics of the logs and the influxdb machine, to store the metrics generated by the app. 
The Test description read as follows:  
"Nabuco is a word class CEO. He need to know which pages are having more access on his website. Nabuco has the
biggest pet shop in the world called NPS(Nabucco's Pet Service). Mr Nabuco has lots of access around the world. His site
is running in 3 AWS(Amazon Web Service) regions being: us-east-1, us-west-2 and ap-south-1. Lucky-ly Nabuco
developers wrote a log line every time a user access a webpage. Nabucos uses the best solution around web ui rendering
web-assembly(WASM) faster than the speed of light. Here is a example of logs you might find:  
/pets/exotic/cats/10 1037825323957 5b019db5-b3d0-46d2-9963-437860af707f 1  
/pets/guaipeca/dogs/1 1037825323957 5b019db5-b3d0-46d2-9963-437860af707g 2  
/tiggers/bid/now 1037825323957 5b019db5-b3d0-46d2-9963-437860af707e 3  
First information is the URL of the site, second we have a timestamp with the user visited that URL. Them right after the
timestamp we have the UUID of the user and finally region code being: us-east-1(1), us-west-2(2) and ap-south-1(3).  
You need to build a solution that receives(ingest) logs via a REST endpoint and is able to calculate in near-real time all the
top metrics like:  
● Metric 1 - Top 3 URL accessed all around the world  
● Metric 2 - Top 3 URL accessed PER region  
● Metric 3 - The URL with less access in all world  
● Metric 4 - Top 3 Access per DAY, WEEK, YEAR (you recive the DAY/WEEK/YEAR by parameter)  
● Metric 5 - The minute with more access in all URLs"  

### My Solution
![alt text](https://i.imgur.com/dYF9bYR.jpg)

### Infra scripts repository link: https://github.com/neves-eduardo/LAA-Infra
### Setting up 
- In the AWS EC2 dashboard create a keypair named 'laachallenge1'
- Clone the Infra Scripts repo.
- Build the Jenkins AMI with 'Packer build jenkinsprovision.json'
- Ansible will print the Jenkins admin password at the end of the job, copy this key for later
- Launch the AMI in an instance. The only special thing you need to do in this step is create a security group with a TCP rule like this
  Custom TCP|TCP|8080|0.0.0.0/0
- In your browser access the following address {instance public DNS}:8080
- Paste the Jenkins admin key here, Jenkins will start configuring itself!


### Jenkins plugins:
  - Recommended Plugins in the standard installation proccess
  - Amazon EC2 Plugin
  - Ansible Plugin
  - Copy Artifact Plugin
  - Packer plugin
  - Gradle Plugin
  - Terraform Plugin
  
### Jenkins Configuration
After installing the Jenkins plugins, we need to configure our jenkins plugins. 
  - Go to "Manage Jenkins" and "Global Tool Configuration", here you'll need to add a valid installation to the following tools:
    Gradle, Ansible, Packer and Terraform. The installation is pretty straightfoward, for each of these tools, click[Tool Name] Installation > Add [tool name], give a name to the installation
   and select the automatic installation option then select the linux amd64 version if necessary.
   - Go to "Manage Jenkins" > "Credentials" > "Global Credential" > "Jenkins(global)" > "Global Credentials(unrestricted)" > "Add Credentials" > selecionar a opção AWS credentials e inserir as chaves nos campos.
   - Go to "Manage Jenkins" > "Configure System" > "Global Properties" > select the "Environment variables" box, "add" and add a variable named "AWS_DEFAULT_REGION" and with the value "us-east-1"
   
### Importing the Jenkins Jobs
  - Go to "Manage Jenkins" and "Jenkins CLI", download the jenkins-cli .jar.
  - At your local machine cd into the LAA-Infra repo directory. 
  Run the following commands:
    - java -jar /location/of/jenkins-cli.jar -s http://{Instance Public DNS}:8080/ -auth admin:{your jenkins secret key} create-job "Build_LAA_App" < location/of/repo/JenkinsMachine/jobs/Build_LAA_App.xml 
    - java -jar /location/of/jenkins-cli.jar -s http://{Instance Public DNS}:8080/ -auth admin:{your jenkins secret key} create-job "Bake LAA Influx" < location/of/repo/JenkinsMachine/jobs/Bake_LAA_Influx.xml  
    - java -jar /location/of/jenkins-cli.jar -s http://{Instance Public DNS}:8080/ -auth admin:{your jenkins secret key} create-job "Bake LAA App" < location/of/repo/JenkinsMachine/jobs/Bake_LAA_App.xml  
    - java -jar /location/of/jenkins-cli.jar -s http://{Instance Public DNS}:8080/ -auth admin:{your jenkins secret key} create-job "Start Influx DB" < location/of/repo/JenkinsMachine/jobs/Start_Influx_DB.xml 
    - java -jar /location/of/jenkins-cli.jar -s http://{Instance Public DNS}:8080/ -auth admin:{your jenkins secret key} create-job "Terraform Infra UP" < location/of/repo/JenkinsMachine/jobs/Terraform_Infra_UP.xml

### Running Jobs
Run the jobs at the following order  
Build LAA App>Bake LAA Influx AMI>Bake LAA App AMI>Terraform Infra UP>Start Influx database

### Instances Running!
Once the instances are all running, you'll need to ssh into the App Instance with the following command:  
ssh -i "{your key}" ec2-user@{instance public dns}
Once you're in the machine edit the *config.properties* file, overwrite the value in db.URL property with the Influxdb EC2 machine public dns and the influx port (8086).

## Log Access Analytics Endpoints
### POST /laa/ingest
Make a POST request with the body of the log (a simple string like this: "/pets/exotic/cats/11 1037825323947 5b0193b5-b3d0-46d2-9963-437860af717f 1")

### GET /laa/health
A healthchecker endpoint, should return status 200 if everything's fine.

### GET laa/metrics/{top}/{region }/{timeUnit}/{duration}
top: as in top10, top3  
region: aws region of the metrics  
timeUnit: Unit of time to divide the metrics  Available timeUnits: NANOSECONDS, MICROSECONDS, MILLISECONDS, SECONDS,MINUTES, HOURS, DAYS  
duration: ammount of time to divide the metrics  

*EXAMPLE JSON RESPONSE*  
{  
  "topURLs": {  
    The TOP x urls of all regions
  },  
  "topURLsByRegion": {  
    The TOP x urls of the selected regions
  },  
  "bottomURL": {  
    The least x accessed urls
  },  
  "topURLByTime": {top url divided by time (days, hours, etc)},  
  "mostAccessedMoment": {most accessed moment in the selected time}  
}  
